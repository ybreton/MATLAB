function [M,P,stats] = CPRBayes(D,distr,varargin)
%CPRBAYES Estimates a changepoint model using marignal likelihood ratios.
%   [M,P] = CPRBayes(D,DISTR) performs model comparisons to divide the time
%   series D into discontinuous subsections, divided by changepoints reported
%   in M, fit to distribution DISTR, and represented by parameters P.
%
%   D is a matrix with rows corresponding to observations, and DISTR is the
%   distribution believed to be responsible for generating observations D.
%   The function interprets D differently depending on this distribution. D
%   is assumed to represent a uniform subdivision of time/trials.
%   Observations in D are also assumed to be exchangeable within each
%   changepoint-delimited subdivision.
%
%   DISTR must be specified by the user, and may be any of the following:
%     ==Discrete Distributions==
%       'binomial' - The data in D are presumed to be individual
%               observations of a Bernoulli process, consisting of the
%               values 0 and 1. All values in D that are greater than 0 are
%               assigned a value of 1.
%       'geometric' - The data in D are presumed to represent the number of
%               failures before the first success on a series of Bernoulli
%               trials.
%       'poisson' - The data in D are presumed to be generated by a Poisson
%               process. D should have a single column, and non-integer
%               values are rounded to the nearest integer value.
%       'multinomial' - The multivariate generalization of the binomial
%               distribution. If D has a single column, it is presumed to
%               be categorical, with each unique value in D constituting an
%               observation in a respective category. If D has more than one
%               column, each column is presumed to be a logical vector
%               corresponding to a predefined category.
%     ==Continuous Distributions==
%       'exponential' - The data in D are presumed to be drawn from an
%               exponential distribution. D should have a single column.
%       'linear' - ???
%       'normal' - The data in D are presumed to be drawn from a Gaussian
%               distribution whose means and precision are unknown. D
%               should have a single column.
%       'uniform' - The data in D are presumed to be drawn from a uniform
%               distribution.
%       'multiple linear' - ???
%       'multivariate normal' - ???
%
%   [M,P,stats] = CPBayes(D,DISTR,'PARAM1',val1,'PARAM2',val2,...) allows you to
%   specify optional parameter name/value pairs to fix certain aspects of
%   the analysis, rather than letting them be inferred from default
%   settings. Parameters are:
%
%      'alpha' - specify the array of hyperparameters that will be used to
%           estimate the normalizing constant in the ratio of marginal
%           model likelihoods. Accepts a row vector of parameter values.
%           See "parameter specifications" below for details associated
%           with a particular distribution.
%
%      'conf' - specify the confidence interval. Default is .95,
%           corresponding to the 95% interval.
%
%      'depth' - forces the algorithm to perform a fixed number of
%           subdivisions, regardless of whether the evidence supports
%           additional cps.
%
%      'knownp' - specify parameters whose value is known. In some cases,
%           this is necessary to achieve a closed-form solution.
%
%      'priorc' - specify the prior probability of a change per
%           observation. If left unspecified, the prior probability is
%           assumed to be 1./length(D) at the outset, and then is increased
%           as changepoints are identified. Assuming multiple changepoints
%           are a reasonable outcome, the default behavior is deliberately
%           conservative to avoid false positives.
%
%      'timestamps' - specify an array of timestamps corresponding to the
%           observations. Times are presumed to appear in a uniform fashion
%           by default. Note that the first timestamp should correspond to
%           the time that observation began (the "0th time"), and not to
%           the first observed event. Thus, the timestamp array should have
%           one more element than D.
%
%      'thresh' - specify the threshold criterion used to assess whether a
%           changepoint is likely given the evidence. By default, any value
%           greater than 1 is taken as evidence in favor of a changepoint,
%           and any value less than 1 is taken as evidence against. Since
%           the threshold is compared to the posterior odds of a
%           changepoint being present, it should be >= 1.
%
%       'dice' - An integer
%
%===OVERALL LOGIC==
%
%   (fill in later)
%
%===MODEL INTERPRETATION==
%
%   M is a column vector listing the last items in each subsection. In all
%   cases, M(1) = 0, and each subdivision of the data spans M(i)+1:M(i+1).
%   Changepoints are presumed to reside between M(i) and M(i)+1, and the
%   vector denotes M(i) as the changepoint merely as a naming convention.
%
%   P is a matrix where each row corresponds to the model parameters in a
%   particular subdivision of the data, and each column refers to a
%   specific distribution parameter for that segment. Given a matrix
%   P(i,j), the identity of each column j varies, as specified below:
%
%     ==Discrete Distribution P parameters==
%       'binomial'
%           P(i,1) = p (Probability of success)
%       'geometric'
%           P(i,1) = p (Probability of success)
%       'poisson'
%           P(i,1) = lambda (rate)
%       'multinomial'
%           P(i,j) = p (Probability of category j), where sum(P(i,:)) = 1
%     ==Continuous Distribution as==
%       'exponential'
%           P(i,1) = lambda (mean)
%       'normal'
%           P(i,1) = mu (mean)
%           P(i,2) = sigma (standard deviation)
%       'linear'
%           ???
%       'uniform'
%           P(i,1) = mn (minimum)
%           P(i,2) = mx (maximum)
%       'multiple linear'
%           ???
%       'multivariate normal'
%           ???
%
%===PARAMETER SPECIFICATION==
%
%   In order to infer the noramlizing constant of a distribition's
%   conjugate prior, it is necessary to estimate the appropriate posteiror
%   hyperparameters. These are defined in part by the evidence, but also by
%   the analyst's prior assumptions. In this function, we denote the prior
%   hyperparameters using the vector a.
%
%   a contains two or more parameters, whose definition differs for
%   each distribution. These parameters can be considered "virtual
%   observations, which are intermixed with actual observations. By
%   default, all distributions begin with all values in a set to one,
%   which constitutes a weak prior. For example, in the binomial case
%   (where each observation is presumed to be a Bernoulli trial) then when
%   a(1) = a(2) = 1 it should be interpreted as "success and
%   failure have 50:50 odds," with one extra observation of each kind added
%   to the data. However, if an analyst has good reasons to think the 50/50
%   odds are correct, then a prior of a(1) = a(2) = 100 would
%   constitute a very strong expectation of equality, effectively adding
%   200 observations to the data.
%   
%   In most cases, an analyst should rely on either strong theoretical or
%   empirical reasons when using strong prior hyperparameters, as these
%   increase the odds of washing out small but real transitions in
%   behavior.
%
%   In the list below, we indicate both the interpretation of the prior
%   hyperparameters and the equation used to estimate the posterior
%   hyperparameters, which are denoted as q(). Other shorthand
%   includes n = length(D); xbar = mean(D); xbar_r = mean(1./D); H_x =
%   Student's t cdf with x df;
%   
%   When a normalzing constant is noted with NC*, the closed-form solution
%   is only approximate.
%   
%     ==Discrete Distribution as==
%       'binomial' = [1 1]
%           Prior Hyperparamters
%               a(1) = ("a" - 1) successes
%               a(2) = ("beta" - 1) failures
%           Posterior Hyperparameters
%               q(1) = a(1) + sum(D)
%               q(2) = a(2) + n - sum(D)
%           Normalizing Constant
%               NC = gamma(a(1) + a(2))./(gamma(a(1)).*gamma(a(2))
%           Posterior Predictive
%               p = q(1)./(q(1)+q(2))
%       'geometric' = [1 1]
%           Prior Hyperparamters
%               a(1) = ("a" - 1) experiments
%               a(2) = ("beta" - 1) failures
%           Posterior Hyperparameters
%               q(1) = a(1) + n
%               q(2) = a(2) + sum(D)
%           Normalizing Constant
%               NC = gamma(a(1) + a(2))./(gamma(a(1)).*gamma(a(2))
%           Posterior Predictive
%               p = (q(1)+n)./(q(1)+q(2)+sum(D)+n)
%       'poisson' = [1 1]
%           Prior Hyperparamters
%               a(1) = "a" total occurances
%               a(2) = "beta" intervals
%           Posterior Hyperparameters
%               q(1) = a(1) + sum(D)
%               q(2) = 1./(a(2) + n)
%           Normalizing Constant
%               NC = (beta.^a).*gamma(a)
%           Posterior Predictive
%               lambda = ???
%       'multinomial' = ones(i,1)
%           Prior Hyperparamters
%               a(i) = ("a_i" - 1) occurances of category i
%           Posterior Hyperparameters
%               q(i) = a(i) + sum(D(:,i))
%           Normalizing Constant
%               NC = gamma(sum(a))./product(gamma(a))
%           Posterior Predictive
%               P = dirichlet(q) 
%     ==Continuous Distribution as==
%       'exponential' = [1 1]
%           Prior Hyperparamters
%               a(1) = "a" observations
%               a(2) = "beta" sum of observations
%           Posterior Hyperparameters
%               q(1) = a(1) + n
%               q(2) = a(2) + sum(D)
%           Normalizing Constant
%               NC = (beta.^a).*gamma(a)
%           Posterior Predictive
%               lambda = (q(2))./(q(1))
%       'linear' = ???
%           Prior Hyperparamters
%               ??
%           Posterior Hyperparameters
%               ??
%           Normalizing Constant
%               ??
%           Posterior Predictive
%               ??
%       'normal' = [? 1 1 1]
%           Prior Hyperparamters
%               a(1) = "mu_0" population mean
%               a(2) = "v" observations for the mean
%               a(3) = (2.*"a" + 1) observations for the precision
%               a(4) = "beta" sum of squares
%           Posterior Hyperparameters
%               q(1) = (a(1).*a(2) + n.*xbar)./(a(2) + n)
%               q(2) = a(2) + n
%               q(3) = a(3) + (n./2)
%               q(4) = a(4) + 0.5.*sum((D-xbar).^2) +
%                           (n.*a(2))./(a(2) + n) .*
%                           ((xbar - a(1)).^2)./2
%           Normalizing Constant
%               NC = (gamma(a)./(beta.^a)).*sqrt((2.*pi)./v)
%           Posterior Predictive
%               mu = q(1);
%               sigma = sqrt((q(4).*(q(2)+1))./(q(2).*q(3)))
%       'uniform' = [1 ? ? ?]
%           Prior Hyperparamters
%               a(1) = "a" observations
%               a(2) = "r1" minimum
%               a(3) = "r2" maximum
%               a(4) = "r2-r1" range; can be specified independently of a(2) and a(3)
%           Posterior Hyperparameters
%               q(1) = a(1) + n
%               q(2) = min([a(2);D])
%               q(3) = max([a(3);D])
%           Normalizing Constant
%               NC = a(1).*(a(1)+1).*((a(3)-a(2)).^a(1))
%           Posterior Predictive
%               mn = min([a(2);D])
%               mx = max([a(3);D])
%       'multivariate normal' = {ones(i,1) 1 1 ones(i)}
%           Prior Hyperparamters
%               a{1} = 
%               a{2} = 
%               a{3} = 
%               a{4} = 
%           Posterior Hyperparameters
%               q{1} = 
%               q{2} = 
%               q{3} = 
%               q{4} = 
%           Normalizing Constant
%               NC = 
%           Posterior Predictive
%               p = 
%
% written by:
% Greg Jensen
% Columbia University (Psychology)
% belarius@gmail.com

%===SETTING UP LOCAL VARIABLES==
FIXED_ALPHA = 0;
CUSTOM_CONF = 0;
FIXED_DEPTH = 0;
KNOWN_P = 0;
FIXED_PRIORC = 0;
FIXED_THRESH = 0;
CUSTOM_TIME = 0;
DICE = 1;

%if size(D,2) > 1
%    error(message('CPBayes:InputDataIsMultivariate'));
%end

len = length(D);
ops = size(D,2);
M = [0;len];
C = [0 0;len len];
R = [0;0];

if nargin < 2
    error(message('CPBayes:TooFewInputs'));
end

distr = lower(distr);
%CHECK DISTRIBUTION AGAINST LIST

if ~isempty(varargin)
    if iscell(varargin{1})
        varargin = varargin{1};
    end
end

if mod(length(varargin),2)
    error(message('CPBayes:BadlyFormedParameters'));
else
    rsargin = reshape(varargin,2,length(varargin)./2)';
    for i = 1:length(rsargin(:,1))
        switch rsargin{i,1}
            case 'alpha'
                FIXED_ALPHA = 1;
                a = rsargin{i,2};
            case 'conf'
                CUSTOM_CONF = 1;
                conf = rsargin{i,2};
            case 'depth'
                FIXED_DEPTH = 1;
                depth = rsargin{i,2};
            case 'knownp'
                KNOWN_P = 1;
                knownp = rsargin{i,2};
                if sum(isnan(knownp)) == length(knownp)
                    error(message('CPBayes:NoFreeParametersRemaining'));
                end
            case 'priorc'
                FIXED_PRIORC = 1;
                p_c(1) = rsargin{i,2}.*len;
                p_c(2) = len;
            case 'timestamps'
                CUSTOM_TIME = 1;
                times = rsargin{i,2};
                if length(times) ~= len+1
                    if length(times) == len
                        error(message('CPBayes:MissingFirstTimestamp'));
                    else
                        error(message('CPBayes:TimestampDataLengthMismatch'));
                    end
                end
                if size(times,2) > 1
                    error(message('CPBayes:TimestampsMustBeUnivariate'));
                end
            case 'thresh'
                FIXED_THRESH = 1;
                thresh = rsargin{i,2};
            case 'dice'
                DICE = rsargin{i,2};
        end
    end
end

data = local_SetupData(D,distr);

if ~FIXED_PRIORC    %Default prior odds of a cp begin at p_c(1)./p_c(2) and are updated as cps are identified
	p_c(1) = -log(0.5);
	p_c(2) = len;
end

if ~FIXED_THRESH    %Default posterior odds ratio threshold is 1, corresponding to even odds
	thresh = 4;
end

if ~CUSTOM_CONF    %Default posterior odds ratio threshold is 1, corresponding to even odds
	conf = .95;
end

if ~CUSTOM_TIME
    times = (0:len)';
end

if ~KNOWN_P         %By default, the knownp array is set to all NaN, with length varying according to the number of distribution parameters
    knownp = local_DefaultParams(distr,ops);
end
    
if ~FIXED_ALPHA     %Each distribution has its own default alpha array, corresponding to a weak assumption with a proper integral
    a = local_DefaultAlpha(data,distr,knownp,ops,times);
end

if ~FIXED_DEPTH
    depth = log2(len)+1;
end

if DICE < 1
    DICE = 1;
else
    DICE = floor(DICE);
end

tic

%===DICING===
if DICE > 1
    x = (1:len)';
    seg = floor((x-1)./(len./(DICE)))+1;
    for i = 1:DICE
        subdex = find(seg==i);
        subargin = [varargin 'dice' 1 'depth' 1];
        [Md,~,statd] = CPBayes(D(subdex,:),distr,subargin);
        if statd.post_ratios(2) > thresh
            M = [M;Md(2)+subdex(1)];
            R = [R;statd.post_ratios(2)];
            C = [C;statd.conf_int(2,1:2)];
        end
    end
    M = sort(M);
end

%===MAIN RECURSIVE ALGORITHM==
count = 1;                      %Denotes the number of additional cps found in each cycle. Begins at 1 to initiate the loop.
deep = 0;
k = [];
q = ones(len,1);
while count > 0;                %When no new cps are identified, the loop ends.
    m = nan(length(M)-1,1);   %Denotes the different subsections of the data, each of which is checked for additional cps.
    c = nan(length(M)-1,2);
    r = nan(length(M)-1,1);
    deep = deep+1;
    k(:,deep) = nan(len,1);
    q(:,deep+1) = ones(len,1);
    for i = 1:length(M)-1
        if q(M(i)+1,deep) == 1
            [cp,ci,k_c] = local_CPBayes_single(data(M(i)+1:M(i+1),:),distr,a,knownp,ops,conf,times);   %The identity and Bayes Factor of a putative cp is identified in segment i.
        else
            k_c = k(M(i)+1:M(i+1),deep-1);
            k(M(i)+1:M(i+1),deep) = k_c;
        end
        BF = exp(k_c);
        BF = sum(BF(~isnan(BF)));
        k(M(i)+1:M(i+1),deep) = k_c;
        if ~isnan(BF) && ~isnan(cp)
            p = p_c(1)./p_c(2);
            p_zero = (1-p).^(M(i+1)-M(i));                          %Odds of zero changes
            p_one = (M(i+1)-M(i)).*p.*(1-p).^(M(i+1)-M(i)-1);       %Odds of exactly one change
            posterior = (p_one./p_zero)*BF;
            m(i) = cp;
            c(i,:) = ci;
            r(i) = posterior;
%            if posterior > thresh || FIXED_DEPTH                                   %If the posterior odds ratio exceeds the threshold and the cp is not a terminal point, it is added to the model.
%                if cp > 1 && cp < M(i+1)-M(i)
%                    m(i) = cp;
%                    c(i,:) = ci;
%                end
%            end
        end
    end
    mtest = ~isnan(m);        % Where were the MLE changes?
    rtest = r>thresh;   % Where were the MLE changes whose MML justifies their inclusion?
    if deep > 1
        test2 = sum(k(:,deep)~=k(:,deep-1));
    else
        test2 = 1;
    end
    if ~test2
        count = 0;
    else
        count = length(find(rtest));
    end
    qm = m + M(1:length(M)-1);      %This step updates the cp indices to reflect the global data indexing, rather than local positions in each segment.
    qc = c + [M(1:length(M)-1) M(1:length(M)-1)];
    if ~FIXED_DEPTH
        for i = find(~rtest)
            q(M(i)+1:M(i+1),deep+1) = 0;
        end
        if count>0
            sortblock = sortrows([M R C;qm(rtest) r(rtest) qc(rtest,:)],1);
        else
            sortblock = sortrows([M R C],1);
        end
    else
        if sum(mtest)>0
            sortblock = sortrows([M R C;qm(mtest) r(mtest) qc(mtest,:)],1);
        else
            sortblock = sortrows([M R C],1);

        end
    end
    M = sortblock(:,1);
    R = sortblock(:,2);
    C = sortblock(:,3:4);
    mlist = unique(M);
    if sum(histc(M,mlist)>1)>0
        for i = 1:length(mlist)
            del = find(M==mlist(i));
            del(R(del)==max(R(del))) = [];
            M(del) = [];
            R(del) = [];
            C(del,:) = [];
        end
    end
    if ~FIXED_PRIORC
        p_c(1) = length(M)-1;       %When p_c is not fixed, the prior odds of finding a cp is updated at the end of each loop.
    end
    if FIXED_DEPTH
        if deep == depth
            count = 0;
        else
            count = 1;
        end
    else
        if count == 0
            deep=deep-1;
        end
    end
end

toc

P = local_EstimateParameters(data,distr,M,knownp,ops,a);

stats = struct('model',{M},'distr',{distr},'params',{P},'timestamps',times,'threshold',{thresh},'post_ratios',{R},'seg_BF',k,'conf',{conf},'conf_int',{C},'prior_change',{p_c(1)./p_c(2)},'prior_model',{a},'depth',{deep});

end

%====SETUP SUBROUTINES====
function knownp = local_DefaultParams(distr,ops)
    switch distr
        case 'binomial'
            knownp = NaN;
        case 'geometric'
            knownp = NaN;
        case 'poisson'
            knownp = NaN;
        case 'multinomial'
            knownp = nan(1,ops);
        case 'exponential'
            knownp = NaN;
        case 'linear'
            knownp = [NaN NaN];
        case 'normal'
            knownp = [NaN NaN];
        case 'uniform'
            knownp = [NaN NaN];
        case 'multiple linear'
            knownp = cell(1,2);
            knownp{1} = NaN;
            knownp{2} = NaN;
        case 'multivariate normal'
            knownp = cell(1,2);
            knownp{1} = NaN;
            knownp{2} = NaN;
    end
end

function a = local_DefaultAlpha(data,distr,knownp,ops,times)
    switch distr
        case 'binomial'
            a = [1 1];
        case 'geometric'
            a = [1 1];
        case 'poisson'
            a = [1 1];
        case 'multinomial'
            a = ones(1,ops);
        case 'exponential'
            a = [1 1];
        case 'linear'
            len = length(data(:,1));
            t = times(2:length(times)) - times(1);
            a = cell(1,5);
            a{1} = [NaN;NaN];
            a{2} = 1;
            a{3} = 2;
            a{4} = inv(0.5*eye(2) + 0.5*ones(2));
            a{5} = [ones(len,1) t];
        case 'normal'
            if isnan(knownp(1)) && isnan(knownp(2))
                a = [median(data) 1 1 1];
            elseif isnan(knownp(1))
                a = [median(data) 1];
            else
                a = [1 1];
            end
        case 'uniform'  %The fourth alpha is a gap delimiter that depends on a(2) and a(3) but can be defined independently.
            a = [1 NaN NaN NaN];
        case 'multiple linear'
            len = length(data(:,1));
            t = times(2:length(times)) - times(1);
            a = cell(ops,5);
            for i = 1:ops
                a{i,1} = [NaN;NaN];
                a{i,2} = 1;
                a{i,3} = 2;
                a{i,4} = inv(0.5*eye(2) + 0.5*ones(2));
                a{i,5} = [ones(len,1) t];
            end
        case 'multivariate normal'
            a = cell(1,4);
            a{1} = median(data);
            a{2} = 1;
            a{3} = ops;
            a{4} = 0.5*eye(ops) + 0.5*ones(ops);
    end
end

function data = local_SetupData(D,distr)
    switch distr
        case 'binomial'
            data = (D>0).*1;
        case 'geometric'
            data = round(D);
        case 'poisson'
            data = round(D);
        case 'multinomial'
            data = zeros(size(D,1),ops);
            for i = 1:ops
                data(:,i) = (D(:,i) > 0).*1;
            end
        case 'exponential'
            data = D;
        case 'linear';
            data = D;
        case 'normal'
            data = D;
        case 'uniform'
            data = D;
        case 'multiple linear';
            data = D;
        case 'multivariate normal'
            data = D;            
    end
end

%====OPERATIONAL SUBROUTINES==
function [cp,ci,k_c] = local_CPBayes_single(data,distr,a,knownp,ops,conf,times)
    len = length(data(:,1));
    qqi = zeros(len,1);
    td = diff(times);
    qqi = zeros(len,1);
%reltime = (times-times(1))./(times(len+1)-times(1));
%td = [nan;log(betacdf(reltime(3:len),0.5,0.5)-betacdf(reltime(2:len-1),0.5,0.5));nan];
    %==Calculate bayes factors==
    for i = 1:len
        [d1 d2] = local_splitter(data,i);
        q1 = local_PosteriorHyper(d1,distr,a,knownp,[1 i-1]);
        q2 = local_PosteriorHyper(d2,distr,a,knownp,[i len]);
        qqi(i) = log(td(i));
%qqi(i) = td(i) - 0.5.*log(len);
        qqi(i) = qqi(i) + local_MarginalModelLikelihood(d1,distr,q1,a,knownp,ops);
        qqi(i) = qqi(i) + local_MarginalModelLikelihood(d2,distr,q2,a,knownp,ops);
    end
    q = local_PosteriorHyper(data,distr,a,knownp,[1 len]);
    qqi = qqi - log(times(len+1)-times(1)) - local_MarginalModelLikelihood(data,distr,q,a,knownp,ops);
%qqi = qqi - local_MarginalModelLikelihood(data,distr,q,a,knownp,ops);
    k_c = qqi;
    %==Pick CP==
    cp = find(qqi==max(qqi))-1;
    if ~isempty(cp) & cp>0
        cp=cp(1);
        conf = log(1-conf);
        lrat = qqi-(qqi(cp+1)+conf);
        ci = [cp cp];
        while(ci(1) > 0 && lrat(ci(1)+1) > 0)
            ci(1) = ci(1)-1;
        end
        while(ci(2) < length(lrat) && lrat(ci(2)+1) > 0)
            ci(2) = ci(2)+1;
        end
%        if strcmp(distr,'linear') || strcmp(distr,'multiple linear')
%            cp = cp+1;
%            ci = ci+1;
%        end
    else
        cp = NaN;
        ci = NaN;
    end
end

function MML = local_MarginalModelLikelihood(data,distr,q,a,knownp,ops)
    %manage incoming variables
%     switch distr
%         case 'binomial'
%             data = [data>0 data==0].*1;
%         case 'uniform'
%             if isnan(knownp(1)) && isnan(knownp(2))
%                 if isnan(a(2))+isnan(a(3)) == 0
%                     a(4) = a(3)-a(2); %In the event that a(2) and a(3) are already defined, these set the value of a(4)
%                 end
%             else
%                 if isnan(knownp(2))
%                     data = data-knownp(1);
%                     a = [a(1) a(3)];
%                 else
%                     data = knownp(2)-data;
%                     a = [a(1) knownp(2)-a(2)];
%                 end
%             end
%     end
%     if isempty(data)
%         %prior hyperparameters
%         q = a;
%     else
%         %posterior hyperparameters
%         len = length(data(:,1));
%         switch distr
%             case 'binomial'
%                 q = sum(data)+a;
%             case 'geometric'
%             	q = [a(1)+len a(2)+sum(data)];
%             case 'poisson'
%             	q = [a(1)+sum(data) a(2)+len];
%             case 'multinomial'
%                 q = sum(data)+a;
%             case 'exponential'
%             	q = [a(1)+len a(2)+sum(data)];
%             case 'linear'
%                 q = local_linear_posth(data,len,a,range);
%             case 'normal'
%                 if isnan(knownp(1)) && isnan(knownp(2))
%                     q = local_normal_mv_posth(data,len,a);
%                 elseif isnan(knownp(1))
%                 	q = local_normal_m_posth(data,len,a,knownp);
%                 elseif isnan(knownp(2))
%                 	q = local_normal_v_posth(data,len,a,knownp);
%                 end
%             case 'uniform'
%                 q = local_uni_posth(data,len,a,knownp);
%             case 'multiple linear'
%                 q = local_multilinear_posth(data,len,a,range);
%             case 'multivariate normal'
%                 q = local_normal_invwishart_posth(data,len,a);
%         end
%     end
    %Calculate MML based on the appropriate conjugate prior
    switch distr
        case 'binomial'
            MML = local_multinom_nc_ln(q);
        case 'geometric'
            MML = local_multinom_nc_ln(q);
        case 'poisson'
            MML = local_gamma_nc_ln(q);
        case 'multinomial'
            MML = local_multinom_nc_ln(q);
        case 'exponential'
            MML = local_gamma_nc_ln(q);
        case 'linear'
            if length(data) < 3
                MML = -inf;
            else
                MML = local_linear_nc_ln(q,a);
            end
        case 'normal'
            if isnan(knownp(1)) && isnan(knownp(2))
            	MML = local_normalgamma_nc_ln(q);
            elseif isnan(knownp(1))
            	MML = local_normal_nc_ln(q);
            elseif isnan(knownp(2))
            	MML = local_gamma_nc_ln(q);
            end
        case 'uniform'
            if isnan(knownp(1)) && isnan(knownp(2))
                if ~isnan(q(4))
                    MML = -1.*( log(q(1)) + log(q(1)+1) + q(1).*log(q(4)));
                else
                    MML = -1.*( log(q(1)) + log(q(1)+1)); %Given no information, the gap is presumed to be 1.
                end
            else
                if ~isnan(q(2))
                    MML = -1.*( log(q(1)) + q(1).*log(q(2)));
                else
                    MML = -1.*( log(q(1)) ); %Given no information, the gap is presumed to be 1.
                end
            end
        case 'multiple linear'
            MML = local_multilinear_nc_ln(q,a);
        case 'multivariate normal'
            if size(data,1) >= ops
                MML = local_normal_invwishart_nc_ln(ops,q);
            elseif size(data,1) >= 1
                m = q{1};
                v = a{4};%0.5*eye(ops) + 0.5*ones(ops);
                MML = -(ops./2).*log(ops);
                for i = 1:size(data,1)
                    MML = MML - (ops./2).*log(2.*pi) - 0.5.*log(det(v));
                    MML = MML - 0.5.*(data(i,:)-m)*inv(v)*(data(i,:)-m)';
                end
            else
                v = a{4};%0.5*eye(ops) + 0.5*ones(ops);
                MML = (-ops./2).*log(2.*pi) - 0.5.*log(det(v));
                MML = MML + (-ops./2).*log(ops);
            end
    end
end

function P = local_EstimateParameters(data,distr,M,knownp,ops,a)
    P = zeros(length(M)-1,1);
    len = length(data);
    switch distr
        case 'binomial'
            for i = 1:length(M)-1
                P(i,1) = sum(data(M(i)+1:M(i+1)))+a(1);
                P(i,1) = P(i,1)./(M(i+1)-M(i)+sum(a));
            end
        case 'geometric'
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1));
                len = M(i+1)-M(i);
                P(i,1) = (a(1) + len)./(a(1) + a(2) + len + sum(d));
            end
        case 'poisson'
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1));
                len = M(i+1)-M(i);
                P(i,1) = (a(1) + sum(d))./(a(2) + len);
            end
        case 'multinomial'
            for i = 1:length(M)-1
                for j = 1:ops
                    P(i,j) = sum(data(M(i)+1:M(i+1),j))+1;
                    P(i,j) = P(i,j)./(M(i+1)-M(i));
                end
            end
        case 'exponential'
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1));
                len = M(i+1)-M(i);
                P(i,1) = (a(2) + sum(d))./(a(1) + len);
            end
        case 'linear'
            P = cell(length(M)-1,2);
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1));
                len = M(i+1)-M(i);
                q = local_linear_posth(d,len,a,[M(i)+1 M(i+1)]);
                P{i,1} = q{1};
                P{i,2} = inv(q{4});
            end
        case 'normal'
            if isnan(knownp(1)) && isnan(knownp(2))
                for i = 1:length(M)-1
                    d = data(M(i)+1:M(i+1));
                    len = M(i+1)-M(i);
                    q = local_normal_mv_posth(d,len,a);
                    P(i,1) = q(1);
                    P(i,2) = sqrt((q(4).*(q(2)+1))./(q(2).*q(3)));
                end
            elseif isnan(knownp(1))
                for i = 1:length(M)-1
                    prec = 1./(knownp(2).^2);
                    d = data(M(i)+1:M(i+1));
                    len = M(i+1)-M(i);
                    q(2) = a(2) + len.*prec;
                    q(1) = (a(1).*a(2) + len.*prec.*mean(d))./q(2);
                    P(i,1) = q(1);
                    P(i,2) = knownp(2);
                end
            elseif isnan(knownp(2))
                for i = 1:length(M)-1
                    d = data(M(i)+1:M(i+1));
                    len = M(i+1)-M(i);
                    q(1) = a(1) + len./2;
                    q(2) = a(2) + sum((d - knownp(1)).^2)./2;
                    P(i,1) = knownp(1);
                    P(i,2) = sqrt(q(2)./q(1));
                end
            end
        case 'uniform'
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1));
                if isnan(knownp(1))
                    P(i,1) = min([a(2);d]);
                else
                    P(i,1) = knownp(1);
                end
                if isnan(knownp(2))
                    P(i,2) = max([a(3);d]);
                else
                    P(i,2) = knownp(2);
                end
            end
        case 'multiple linear'
            P = cell(length(M)-1,2);
            ops = length(data(1,:));
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1),:);
                len = M(i+1)-M(i);
                q = local_multilinear_posth(d,len,a,[M(i)+1 M(i+1)]);
                P{i,1} = cell(1,ops);
                P{i,2} = cell(1,ops);
                for j = 1:ops
                    P{i,1}(j) = {q{j,1}};
                    P{i,2}(j) = {inv(q{j,4})};
                end
            end
        case 'multivariate normal'
            P = cell(length(M)-1,2);
            for i = 1:length(M)-1
                d = data(M(i)+1:M(i+1),:);
                len = M(i+1)-M(i);
                q = local_normal_invwishart_posth(d,len,a);
                P{i,1} = q{1};
                P{i,2} = q{4}./(q{3} - ops - 1);
            end
    end
end

%====POSTERIOR HYPERPARAMETER SUBROUTINES====
function q = local_PosteriorHyper(data,distr,a,knownp,range)
    switch distr
        case 'binomial'
            data = [data>0 data==0].*1;
        case 'uniform'
            if isnan(knownp(1)) && isnan(knownp(2))
                if isnan(a(2))+isnan(a(3)) == 0
                    a(4) = a(3)-a(2); %In the event that a(2) and a(3) are already defined, these set the value of a(4)
                end
            else
                if isnan(knownp(2))
                    data = data-knownp(1);
                    a = [a(1) a(3)];
                else
                    data = knownp(2)-data;
                    a = [a(1) knownp(2)-a(2)];
                end
            end
    end
    if isempty(data)
        %prior hyperparameters
        q = a;
    else
        %posterior hyperparameters
        len = length(data(:,1));
        switch distr
            case 'binomial'
                q = sum(data)+a;
            case 'geometric'
            	q = [a(1)+len a(2)+sum(data)];
            case 'poisson'
            	q = [a(1)+sum(data) a(2)+len];
            case 'multinomial'
                q = sum(data)+a;
            case 'exponential'
            	q = [a(1)+len a(2)+sum(data)];
            case 'linear'
                q = local_linear_posth(data,len,a,range);
            case 'normal'
                if isnan(knownp(1)) && isnan(knownp(2))
                    q = local_normal_mv_posth(data,len,a);
                elseif isnan(knownp(1))
                	q = local_normal_m_posth(data,len,a,knownp);
                elseif isnan(knownp(2))
                	q = local_normal_v_posth(data,len,a,knownp);
                end
            case 'uniform'
                q = local_uni_posth(data,len,a,knownp);
            case 'multiple linear'
                q = local_multilinear_posth(data,len,a,range);
            case 'multivariate normal'
                q = local_normal_invwishart_posth(data,len,a);
        end
    end
end

function q = local_normal_m_posth(d,len,a,knownp)
    q = zeros(1,2);
    q(1) = (a(1).*a(2) + len.*knownp(2).*mean(d))./(a(2) + len.*knownp(2));
    q(2) = a(2) + len.*knownp(2);
end

function q = local_normal_v_posth(d,len,a,knownp)
    q = zeros(1,2);
    q(1) = a(1) + len./2;
    q(2) = a(2) + sum((d-knownp(1)).^2)./2;
end

function q = local_normal_mv_posth(d,len,a)
    q = zeros(1,4);
    mn = mean(d);
    q(1) = (a(2).*a(1) + len.*mn)./(a(2) + len);
    q(2) = a(2) + len;
    q(3) = a(3) + len./2;
    q(4) = a(4) + 0.5.*sum((d-mn).^2) + ((len.*a(2).*((mn - a(1)).^2))./(2.*(a(2) + len)));
end

function q = local_linear_posth(d,len,a,range)
    warning('off','MATLAB:singularMatrix')
    x = a{5}(range(1):range(2),:);
    if length(x(1,:)>1)
        for i = 2:length(x(1,:))
           x(:,i) = x(:,i)-x(1,i); 
        end
    end
    b = ((x'*x)\x')*d; % ((x'*x)\x') is equivalent to inv(x'*x)*x'
    if isnan(a{1}(1))
        a{1}(1) = d(1);
        for i = 2:length(a{1})
            a{1}(i) = 0;
        end
    end
    q = cell(1,4);
	q{4} = x'*x + a{4};
	q{2} = a{2} + len./2;
	q{1} = (x'*x + a{4})\(x'*x*b + a{4}*a{1}); % (x'*x + a{4})\(x'*x*b + a{4}*a{1}) is equivalent to inv(x'*x + a{4})*(x'*x*b + a{4}*a{1})
	q{3} = a{3} + 0.5.*(d'*d + a{1}'*a{4}*a{1} - q{1}'*q{4}*q{1});
    warning('on','MATLAB:singularMatrix')
end

function q = local_multilinear_posth(d,len,a,range)
    ops = length(d(1,:));
    q = cell(ops,4);
    for i = 1:ops
        q(i,:) = local_linear_posth(d(:,i),len,a(i,:),range);
    end
end

function q = local_uni_posth(d,len,a,knownp)
    if isnan(knownp(1)) && isnan(knownp(2))
        if isnan(a(4))
            if isnan(a(3))
                a(4) = 1;
            else
                a(4) = a(3)-a(2);
            end
        end
        q(1) = a(1) + len;
        if isnan(a(2))
            q(2) = min(d);
        else
            q(2) = min([d;a(2)]);
        end
        if isnan(a(3))
        	q(3) = max(d);
    	else
        	q(3) = max([d;a(3)]);
        end
        if q(3)-q(2) < a(4)
            q(4) = a(4);
        else
            q(4) = q(3)-q(2);
        end
    else
        q(1) = a(1) + len;
        if isnan(a(2))
            q(2) = max(d);
        else
            q(2) = max([d;a(2)]);
        end
    end
end

function q = local_normal_invwishart_posth(d,len,a)
    q = cell(1,4);
    q{1} = (a{2}./(a{2}+len))*a{1} + (len./(a{2}+len))*mean(d);
    q{2} = a{2} + len;
    q{3} = a{3} + len;
    q{4} = inv(a{4}) + cov(d).*len + ((len.*a{2})./(len + a{2}))*(mean(d)-a{1})*(mean(d)-a{1})';

end


%====NORMALIZING CONSTANT SUNROUTINES====
function out = local_gamma_nc_ln(a)
%local_multinom_nc_ln Returns the log normalizing constant of the gamma
%   a(1) = shape
%   a(2) = rate
    out = gammaln(a(1)) - a(1).*log(a(2));
end

function out = local_multinom_nc_ln(a)
%local_multinom_nc_ln Returns the log normalizing constant of the dirichlet-multinomial
%   a  = parameters
    if ~isempty(find(a==0, 1))
        out = 0;
    else
        out = sum(gammaln(a)) - gammaln(sum(a));
    end
end

function out = local_normal_nc_ln(a)
%local_multinom_nc_ln Returns the log normalizing constant of the gamma
%   a(1) = shape
%   a(2) = rate
    out = (log((2.*pi)./a(2)) + a(2).*(a(1).^2))./2;
end

function out = local_normalgamma_nc_ln(a)
%local_multinom_nc_ln Returns the log normalizing constant of the normal-gamma
%   a  = parameters
    out = gammaln(a(3)) - a(3).*log(a(4)) + 0.5.*(log(2.*pi) - log(a(2)));
end

function out = local_linear_nc_ln(q,a)
    len = 2.*(q{2} - a{2});
    out = (-len./2).*log(2.*pi()) + 0.5.*log(det(a{4})./det(q{4})) + a{2}.*log(a{3}) - q{2}.*log(q{3}) + gammaln(q{2}) - gammaln(a{2});
end

function out = local_multilinear_nc_ln(q,a)
    out = 0;
    for i = 1:length(q(:,1))
        qx = q(i,:);
        ax = a(i,:);
        out = out + local_linear_nc_ln(qx,ax);
    end
end

function out = local_normal_invwishart_nc_ln(ops,a)
%local_multinom_nc_ln Returns the log normalizing constant of the gamma
%   a  = parameters

%out = 0.5*ops.*log(a{2}./(2.*pi()));
%out = out + 0.5.*a{3}.*ops.*log(2) + 0.25.*ops.*(ops-1).*log(pi());
%for i = 1:ops
%    out = out + gammaln((a{3} + 1 - i)./2);
%end
%out = out - det(a{4}).^(a{3}./2);

out = 0;
out = out + 0.5.*a{3}.*ops.*log(2);
out = out + 0.25.*ops.*(ops-1).*log(pi());
for i = 1:ops
    out = out + gammaln((a{3} + 1 - i)./2);
end
out = out + 0.5.*ops.*log((2.*pi())./a{2});
out = out - 0.5.*a{2}.*log(det(a{4}));

end


%====MISC SUBROUTINES====
function [d1, d2] = local_splitter(data,i)
%local_splitter Returns the subsets of the the data and their respective
%lengths
    len = length(data(:,1));
    if i == 1
        d1 = [];
    else
        d1 = data(1:i-1,:);
    end
    d2 = data(i:len,:);
end
